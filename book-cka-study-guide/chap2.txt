chapter 2

keywords

	rbac
	kubeadm, installation
	upgrade versions
	backup etcd
	ha

rbac: subject -- verb --> api resources

authn strategies

	x.509 client cert
	basic auth
	bearer token

create a cert for user

	1	mkdir cert && cd cert

	2	openssl genrsa -out johndoe.key 2048   // output: johndoe.key

	3	openssl req -new -key johndoe.key -out johndoe.csr -subj "/CN=johndoe/O=cka-study-guide"   // output: johndoe.csr

	4	openssl x509 -req -in johndoe.csr -CA %userprofile%/.minikube/ca.crt -CAkey %userprofile%/.minikube/ca.key -out johndoe.crt -CAcreateserial -days 364   // output: johndoe.crt

	5	k config set-credentials johndoe --client-certificate=johndoe.crt --client-key=johndoe.key
		k config set-context johndoe-context --cluster=minikube --user=johndoe

	6	k config use-context johndoe-context
		k config current-context

service account

	// default sa
	default

	// create a new sa
	k create serviceaccount build-bot

	// listing sa
	k get serviceaccounts
	k get serviceaccount
	k get sa

	// details
	k describe sa build-bot

	// secrets
	k get secrets

	// assigning sa to pod (--serviceaccount will be removed in 1.24)
	k run build-observer --image=alpine --restart=Never --serviceaccount=build-bot

understanding rbac

keywords

	resource - role - rolebinding - user/group
	role, rolebinding
	clusterrole, clusterrolebinding

default clusterrole

	cluster-admin
	admin
	edit
	view

	k get clusterrole
	NAME                                                                   CREATED AT
	admin                                                                  2022-04-14T00:46:59Z
	cluster-admin                                                          2022-04-14T00:46:59Z
	edit                                                                   2022-04-14T00:47:00Z
	kubeadm:get-nodes                                                      2022-04-14T00:47:04Z
	system:aggregate-to-admin                                              2022-04-14T00:47:00Z
	system:aggregate-to-edit                                               2022-04-14T00:47:00Z
	system:aggregate-to-view                                               2022-04-14T00:47:00Z
	system:auth-delegator                                                  2022-04-14T00:47:00Z
	system:basic-user                                                      2022-04-14T00:46:59Z
	system:certificates.k8s.io:certificatesigningrequests:nodeclient       2022-04-14T00:47:00Z
	system:certificates.k8s.io:certificatesigningrequests:selfnodeclient   2022-04-14T00:47:00Z
	system:certificates.k8s.io:kube-apiserver-client-approver              2022-04-14T00:47:01Z
	system:certificates.k8s.io:kube-apiserver-client-kubelet-approver      2022-04-14T00:47:01Z
	system:certificates.k8s.io:kubelet-serving-approver                    2022-04-14T00:47:01Z
	system:certificates.k8s.io:legacy-unknown-approver                     2022-04-14T00:47:01Z
	system:controller:attachdetach-controller                              2022-04-14T00:47:01Z
	system:controller:certificate-controller                               2022-04-14T00:47:01Z
	system:controller:clusterrole-aggregation-controller                   2022-04-14T00:47:01Z
	system:controller:cronjob-controller                                   2022-04-14T00:47:01Z
	system:controller:daemon-set-controller                                2022-04-14T00:47:01Z
	system:controller:deployment-controller                                2022-04-14T00:47:01Z
	system:controller:disruption-controller                                2022-04-14T00:47:01Z
	system:controller:endpoint-controller                                  2022-04-14T00:47:01Z
	system:controller:endpointslice-controller                             2022-04-14T00:47:01Z
	system:controller:endpointslicemirroring-controller                    2022-04-14T00:47:01Z
	system:controller:ephemeral-volume-controller                          2022-04-14T00:47:01Z
	system:controller:expand-controller                                    2022-04-14T00:47:01Z
	system:controller:generic-garbage-collector                            2022-04-14T00:47:01Z
	system:controller:horizontal-pod-autoscaler                            2022-04-14T00:47:01Z
	system:controller:job-controller                                       2022-04-14T00:47:01Z
	system:controller:namespace-controller                                 2022-04-14T00:47:01Z
	system:controller:node-controller                                      2022-04-14T00:47:01Z
	system:controller:persistent-volume-binder                             2022-04-14T00:47:01Z
	system:controller:pod-garbage-collector                                2022-04-14T00:47:01Z
	system:controller:pv-protection-controller                             2022-04-14T00:47:01Z
	system:controller:pvc-protection-controller                            2022-04-14T00:47:01Z
	system:controller:replicaset-controller                                2022-04-14T00:47:01Z
	system:controller:replication-controller                               2022-04-14T00:47:01Z
	system:controller:resourcequota-controller                             2022-04-14T00:47:01Z
	system:controller:root-ca-cert-publisher                               2022-04-14T00:47:02Z
	system:controller:route-controller                                     2022-04-14T00:47:01Z
	system:controller:service-account-controller                           2022-04-14T00:47:01Z
	system:controller:service-controller                                   2022-04-14T00:47:01Z
	system:controller:statefulset-controller                               2022-04-14T00:47:01Z
	system:controller:ttl-after-finished-controller                        2022-04-14T00:47:01Z
	system:controller:ttl-controller                                       2022-04-14T00:47:01Z
	system:coredns                                                         2022-04-14T00:47:05Z
	system:discovery                                                       2022-04-14T00:46:59Z
	system:heapster                                                        2022-04-14T00:47:00Z
	system:kube-aggregator                                                 2022-04-14T00:47:00Z
	system:kube-controller-manager                                         2022-04-14T00:47:00Z
	system:kube-dns                                                        2022-04-14T00:47:00Z
	system:kube-scheduler                                                  2022-04-14T00:47:01Z
	system:kubelet-api-admin                                               2022-04-14T00:47:00Z
	system:monitoring                                                      2022-04-14T00:46:59Z
	system:node                                                            2022-04-14T00:47:00Z
	system:node-bootstrapper                                               2022-04-14T00:47:00Z
	system:node-problem-detector                                           2022-04-14T00:47:00Z
	system:node-proxier                                                    2022-04-14T00:47:01Z
	system:persistent-volume-provisioner                                   2022-04-14T00:47:00Z
	system:public-info-viewer                                              2022-04-14T00:46:59Z
	system:service-account-issuer-discovery                                2022-04-14T00:47:01Z
	system:volume-scheduler                                                2022-04-14T00:47:00Z
	view                                                                   2022-04-14T00:47:00Z

	// create roles (role <=> resources)
	k create role read-only --verb=list,get,watch --resource=pods,deployments,services

	// listing roles
	k get roles
	k get role

	k get role read-only
	k get role read-only -o yaml
	k get role read-only -o json

	k describe role read-only
	Name:         read-only
	Labels:       <none>
	Annotations:  <none>
	PolicyRule:
	  Resources         Non-Resource URLs  Resource Names  Verbs
	  ---------         -----------------  --------------  -----
	  pods              []                 []              [list get watch]
	  services          []                 []              [list get watch]
	  deployments.apps  []                 []              [list get watch]

	// create rolebindings (role <=> user)
	k create rolebinding read-only-binding --role=read-only --user=johndoe

	// list rolebindings
	k get rolebindings
	k get rolebinding

	k describe rolebinding read-only-binding
	Name:         read-only-binding
	Labels:       <none>
	Annotations:  <none>
	Role:
	  Kind:  Role
	  Name:  read-only
	Subjects:
	  Kind  Name     Namespace
	  ----  ----     ---------
	  User  johndoe

seeing the rbac rules in effect

	k config current-context

	k create deployment myapp --image=nginx --port=80 --replicas=2

	k config use-context johndoe-context

	k get deployments   // Expected: normal result. Actual: prompt username and password

	k get replicasets   // Expected: Forbidden error. Actual: prompt username and password

	k delete deployment myapp   // Expected: Forbidden error. Actual: prompt username and password

checking all permissions

	k auth can-i --list
	Resources                                       Non-Resource URLs   Resource Names   Verbs
	*.*                                             []                  []               [*]
													[*]                 []               [*]
	selfsubjectaccessreviews.authorization.k8s.io   []                  []               [create]
	selfsubjectrulesreviews.authorization.k8s.io    []                  []               [create]
													[/api/*]            []               [get]
													[/api]              []               [get]
													[/apis/*]           []               [get]
													[/apis]             []               [get]
													[/healthz]          []               [get]
													[/healthz]          []               [get]
													[/livez]            []               [get]
													[/livez]            []               [get]
													[/openapi/*]        []               [get]
													[/openapi]          []               [get]
													[/readyz]           []               [get]
													[/readyz]           []               [get]
													[/version/]         []               [get]
													[/version/]         []               [get]
													[/version]          []               [get]
													[/version]          []               [get]

	k auth can-i --list --as johndoe
	Resources                                       Non-Resource URLs   Resource Names   Verbs
	selfsubjectaccessreviews.authorization.k8s.io   []                  []               [create]
	selfsubjectrulesreviews.authorization.k8s.io    []                  []               [create]
													[/api/*]            []               [get]
													[/api]              []               [get]
													[/apis/*]           []               [get]
													[/apis]             []               [get]
													[/healthz]          []               [get]
													[/healthz]          []               [get]
													[/livez]            []               [get]
													[/livez]            []               [get]
													[/openapi/*]        []               [get]
													[/openapi]          []               [get]
													[/readyz]           []               [get]
													[/readyz]           []               [get]
													[/version/]         []               [get]
													[/version/]         []               [get]
													[/version]          []               [get]
													[/version]          []               [get]
	pods                                            []                  []               [list get watch]
	services                                        []                  []               [list get watch]
	deployments.apps                                []                  []               [list get watch]


	k auth can-i list pods --as johndoe
	yes

	k auth can-i get pods --as johndoe
	yes

	k auth can-i delete pods --as johndoe
	no

	k auth can-i list pods --as minikube
	no

	k auth can-i get pods --as minikube
	no

aggregating rbac rules

	k create ns rbac-example

rule 1

	k create clusterrole list-pods --verb=list --resource=pods  -n rbac-example

	k get clusterrole list-pods -o yaml
	apiVersion: rbac.authorization.k8s.io/v1
	kind: ClusterRole
	metadata:
	  creationTimestamp: "2022-04-20T23:34:48Z"
	  name: list-pods
	  resourceVersion: "416094"
	  uid: 2b5f074a-44ba-499a-8b44-7928f601531b
	rules:
	- apiGroups:
	  - ""
	  resources:
	  - pods
	  verbs:
	  - list

	k edit clusterrole list-pods
	clusterrole.rbac.authorization.k8s.io/list-pods edited

	k get clusterrole list-pods -o yaml
	apiVersion: rbac.authorization.k8s.io/v1
	kind: ClusterRole
	metadata:
	  creationTimestamp: "2022-04-20T23:34:48Z"
+	  labels:
+		rbac-pod-list: "true"
	  name: list-pods
	  resourceVersion: "416094"
	  uid: 2b5f074a-44ba-499a-8b44-7928f601531b
	rules:
	- apiGroups:
	  - ""
	  resources:
	  - pods
	  verbs:
	  - list

	k describe clusterrole list-pods
	Name:         list-pods
	Labels:       rback-pod-list=true
	Annotations:  <none>
	PolicyRule:
	  Resources  Non-Resource URLs  Resource Names  Verbs
	  ---------  -----------------  --------------  -----
	  pods       []                 []              [list]

rule 2

	k create clusterrole delete-services --verb=delete --resource=services -n rbac-example

	k get clusterrole delete-services -o yaml
	apiVersion: rbac.authorization.k8s.io/v1
	kind: ClusterRole
	metadata:
	  creationTimestamp: "2022-04-20T23:39:48Z"
	  name: delete-services
	  resourceVersion: "416274"
	  uid: cf80129c-7139-454a-8db0-9de13c5bad7b
	rules:
	- apiGroups:
	  - ""
	  resources:
	  - services
	  verbs:
	  - delete

	k edit clusterrole delete-services

	k get clusterrole delete-services -o yaml
	apiVersion: rbac.authorization.k8s.io/v1
	kind: ClusterRole
	metadata:
	  creationTimestamp: "2022-04-20T23:39:48Z"
+	  labels:
+		rbac-service-delete: "true"
	  name: delete-services
	  resourceVersion: "416374"
	  uid: cf80129c-7139-454a-8db0-9de13c5bad7b
	rules:
	- apiGroups:
	  - ""
	  resources:
	  - services
	  verbs:
	  - delete

aggregated rule 3

	k create clusterrole pods-services-aggregation-rules --aggregation-rule="rbac-pod-list=true" --aggregation-rule="rbac-service-delete=true" -n rbac-example --dry-run=client -o yaml
	aggregationRule:
	  clusterRoleSelectors:
	  - matchLabels:
		  rbac-pod-list: "true"
		  rbac-service-delete: "true"
	apiVersion: rbac.authorization.k8s.io/v1
	kind: ClusterRole
	metadata:
	  creationTimestamp: null
	  name: pods-services-aggregation-rules
	rules: null

	k describe clusterrole pods-services-aggregation-rules -n rbac-example
	Name:         pods-services-aggregation-rules
	Labels:       <none>
	Annotations:  <none>
	PolicyRule:
	  Resources  Non-Resource URLs  Resource Names  Verbs
	  ---------  -----------------  --------------  -----

	k edit clusterrole pods-services-aggregation-rules -o yaml

	k get clusterrole pods-services-aggregation-rules -o yaml
	aggregationRule:
	  clusterRoleSelectors:
	  - matchLabels:
		  rbac-pod-list: "true"
+	  - matchLabels:
		  rbac-service-delete: "true"
	apiVersion: rbac.authorization.k8s.io/v1
	kind: ClusterRole
	metadata:
	  creationTimestamp: "2022-04-20T23:49:03Z"
	  name: pods-services-aggregation-rules
	  resourceVersion: "416660"
	  uid: e85aacc4-e99e-40a0-abfb-31b82a1cce92
	rules: null

	k describe clusterrole pods-services-aggregation-rules -n rbac-example
	Name:         pods-services-aggregation-rules
	Labels:       <none>
	Annotations:  <none>
	PolicyRule:
	  Resources  Non-Resource URLs  Resource Names  Verbs
	  ---------  -----------------  --------------  -----
	  services   []                 []              [delete]
	  pods       []                 []              [list]

creating and managing a kubernetes cluster ('kubeadm join' was not successful though)

	master01			worker01			worker02
	--------			--------			--------
	kubeadm
	cri-o
						kubeadm
						cri-o
	kubeadm init
						kubeadm join
											kubeadm
											cri-o
											kubeadm join

#1
	# ubuntu 20.04, cri-o, 1 master, 2 worker, pod-network-cidr=10.244.0.0/16
	# https://computingforgeeks.com/deploy-kubernetes-cluster-on-ubuntu-with-kubeadm/

	export POD_NETWORK=10.244.0.0

	#
	# kubernetes (master, worker)
	#

	sudo apt update
	# sudo apt -y full-upgrade
	# [ -f /var/run/reboot-required ] && sudo reboot -f
	sudo apt -y install curl apt-transport-https
	curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
	echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

	sudo apt update
	sudo apt -y install vim git curl wget kubelet kubeadm kubectl
	sudo apt-mark hold kubelet kubeadm kubectl

	kubectl version --client && kubeadm version

	sudo sed -i '/swap/ s/^\(.*\)$/#\1/g' /etc/fstab
	grep -v '^#' /etc/fstab | grep swap || echo OK
	sudo swapoff -a

	# Enable kernel modules
	sudo modprobe overlay
	sudo modprobe br_netfilter

	# Add some settings to sysctl
	sudo tee /etc/sysctl.d/kubernetes.conf << EOF
	net.bridge.bridge-nf-call-ip6tables = 1
	net.bridge.bridge-nf-call-iptables = 1
	net.ipv4.ip_forward = 1
	EOF

	# Reload sysctl
	sudo sysctl --system

	#
	# cri-o (master, worker)
	#

	# Ensure you load modules
	sudo modprobe overlay
	sudo modprobe br_netfilter

	# Set up required sysctl params
	sudo tee /etc/sysctl.d/kubernetes.conf << EOF
	net.bridge.bridge-nf-call-ip6tables = 1
	net.bridge.bridge-nf-call-iptables = 1
	net.ipv4.ip_forward = 1
	EOF

	# Reload sysctl
	sudo sysctl --system

	# Add Cri-o repo
	tee ~/cri-o-repo.sh << EOF
	export OS="xUbuntu_20.04"
	export VERSION=1.23
	echo "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/\$OS/ /" > /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
	echo "deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/\$VERSION/\$OS/ /" > /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:$VERSION.list
	curl -sL https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable:cri-o:\$VERSION/\$OS/Release.key | apt-key add -
	curl -sL https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/\$OS/Release.key | apt-key add -
	EOF
	sudo sh -x ~/cri-o-repo.sh

	# Install CRI-O
	sudo apt update
	sudo apt install -y cri-o cri-o-runc

	# Update CRI-O CIDR subnet
	sudo sed -i "s/10.85.0.0/$POD_NETWORK/g" /etc/cni/net.d/100-crio-bridge.conf

	# Start and enable Service
	sudo systemctl daemon-reload
	sudo systemctl restart crio
	sudo systemctl enable crio
	sudo systemctl status crio --no-pager

#2

	# https://computingforgeeks.com/deploy-kubernetes-cluster-on-ubuntu-with-kubeadm/

	export POD_NETWORK=10.244.0.0

	#
	# init master
	#

	lsmod | grep br_netfilter
	sudo systemctl enable kubelet
	sudo kubeadm config images pull --cri-socket /var/run/crio/crio.sock

	# sudo vi /etc/hosts
	# 192.168.1.65 k8s-master01
	# 192.168.1.66 k8s-worker01
	# 192.168.1.67 k8s-worker02

	# sudo kubeadm init --pod-network-cidr=$POD_NETWORK/16 --cri-socket /var/run/crio/crio.sock --upload-certs --control-plane-endpoint=192.168.1.65
	sudo kubeadm init --pod-network-cidr=$POD_NETWORK/16

	mkdir -p $HOME/.kube
	sudo cp -f /etc/kubernetes/admin.conf $HOME/.kube/config
	sudo chown $(id -u):$(id -g) $HOME/.kube/config

	kubectl cluster-info

	# cni
	kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml
	kubectl create -f https://docs.projectcalico.org/manifests/custom-resources.yaml

	watch kubectl get pods --all-namespaces

#3

	#
	# second master
	#

	# sudo vi /etc/hosts
	# 192.168.1.65 kube-master
	# 192.168.1.66 kube-worker-1
	# 192.168.1.67 kube-worker-2

	kubeadm join k8s-master01:6443 \
		--token sr4l2l.2kvot0pfalh5o4ik \
		--discovery-token-ca-cert-hash sha256:c692fb047e15883b575bd6710779dc2c5af8073f7cab460abd181fd3ddb29a18 \
		--control-plane

#4

	#
	# worker node
	#

	# sudo vi /etc/hosts
	# 192.168.1.65 kube-master
	# 192.168.1.66 kube-worker-1
	# 192.168.1.67 kube-worker-2

	export POD_NETWORK=10.244.0.0

	kubeadm join k8s-master01:6443 \
	  --token sr4l2l.2kvot0pfalh5o4ik \
	  --discovery-token-ca-cert-hash sha256:c692fb047e15883b575bd6710779dc2c5af8073f7cab460abd181fd3ddb29a18

managing a highly-available cluster

	master-lb
		master01
		master02
		master03
	worker01
	worker02
	worker03

	master01			master02			worker01			worker02
	--------			--------			--------			--------
	kubeadm
	cri-o
											kubeadm
											cri-o
	kubeadm init
											kubeadm join
																kubeadm
																cri-o
																kubeadm join
						kubeadm join

	kubeadm join k8s-master01:6443 \
		--token sr4l2l.2kvot0pfalh5o4ik \
		--discovery-token-ca-cert-hash sha256:c692fb047e15883b575bd6710779dc2c5af8073f7cab460abd181fd3ddb29a18 \
		--control-plane

external etcd topology

	master-lb
		master01 -> etcd01
		master02 -> etcd02
		master03 -> etcd03
	worker01
	worker02
	worker03

upgrading a cluster version

	1.18.0 to 1.19.0

#1 upgrade master node

	// current node version: 1.18.0
	kubectl get nodes

	sudo apt update

	// see available versions: want to upgrade to 1.19.0
	sudo apt-cache madison kubeadm

	// upgrade method 1
	sudo apt-mark unhold kubeadm
	sudo apt-get update
	sudo apt-get install -y kubeadm=1.19.0-00
	sudo apt-mark hold kubeadm

	// upgrade method 2
	sudo apt-get update
	sudo apt-get install -y --allow-change-held-packages kubeadm=1.19.0-00

	sudo kubeadm upgrade plan

	sudo kubeadm upgrade apply v1.19.0

	// upgrade cni as well here

	sudo drain kube-master --ignore-daemonsets

	// upgrade
	sudo apt-mark unhold kubelet kubectl
	sudo apt-get update
	sudo apt-get install -y kubelet=1.19.0-00 kubectl=1.19.0-00
	sudo apt-mark hold kubelet kubectl

	//restart
	sudo systemctl daemon-reload
	sudo systemctl resteart kubelet

	// reenable control plain
	kubectl uncordon kube-master

#1 upgrade worker node

	// upgrade kubeadm
	sudo apt-mark unhold kubeadm
	sudo apt-get update
	sudo apt-get install -y kubeadm=1.19.0-00
	sudo apt-mark hold kubeadm

	// upgrade node
	sudo kubeadm upgrade node

	// drain
	sudo drain kube-worker-1 --ignore-daemonsets

	// upgrade kubelet and kubectl
	sudo apt-mark unhold kubelet kubectl
	sudo apt-get update
	sudo apt-get install -y kubelet=1.19.0-00 kubectl=1.19.0-00
	sudo apt-mark hold kubelet kubectl

	// restart
	sudo systemctl daemon-reload
	sudo systemctl resteart kubelet

	// reenable worker node
	kubectl uncordon kube-worker-1

backing up and restoring etcd

	etcd01
	etcd02

#1 on kube-master

	sudo apt update
	sudo apt install -y etcd-client

	etcdctl version

	// get etcd pod name: etcd-kube-master
	kubectl get pod -n kube-system

		NAME                                   READY   STATUS    RESTARTS   AGE
		coredns-64897985d-t9rxz                0/1     Pending   0          85m
		coredns-64897985d-zjtxq                0/1     Pending   0          85m
		etcd-k8s-master01                      1/1     Running   0          85m <==
		kube-apiserver-k8s-master01            1/1     Running   0          85m
		kube-controller-manager-k8s-master01   1/1     Running   0          85m
		kube-proxy-kbn7v                       1/1     Running   0          85m
		kube-scheduler-k8s-master01            1/1     Running   0          85m

	kubectl describe pod etcd-k8s-master01 -n kube-system
		...
		Command:
			  etcd
			  --advertise-client-urls=https://10.0.2.15:2379
			  --cert-file=/etc/kubernetes/pki/etcd/server.crt
			  --client-cert-auth=true
			  --data-dir=/var/lib/etcd
			  --initial-advertise-peer-urls=https://10.0.2.15:2380
			  --initial-cluster=k8s-master01=https://10.0.2.15:2380
			  --key-file=/etc/kubernetes/pki/etcd/server.key
			  --listen-client-urls=https://127.0.0.1:2379,https://10.0.2.15:2379
			  --listen-metrics-urls=http://127.0.0.1:2381
			  --listen-peer-urls=https://10.0.2.15:2380
			  --name=k8s-master01
			  --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt
			  --peer-client-cert-auth=true
			  --peer-key-file=/etc/kubernetes/pki/etcd/peer.key
			  --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
			  --snapshot-count=10000
			  --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt

	sudo ETCDCTL_API=3 etcdctl --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key snapshot save /opt/etcd-backup.db

#2 restoring etcd

	ls -l /opt/etcd-backup.db
	sudo ETCDCTL_API=3 etcdctl --data-dir=/var/lib/from-backup snapshot restore /opt/etcd-backup.db
	sudo ls -l /var/lib/from-backup

	// edit .spec.volumes[].hostPath.path: /var/lib/etcd => /var/lib/from-backup
	cd /etc/kubernetes/manifests
	sudo vi etcd.yaml

	// restart
	kubectl delete pod etcd-k8s-master01 -n kube-system

	// log
	kubectl log -f etcd-k8s-master01 -n kube-system

	백업본으로는 pod 상태가 Running이 안 되네. 계속 Pending 이었음. 구성 원복했음.

